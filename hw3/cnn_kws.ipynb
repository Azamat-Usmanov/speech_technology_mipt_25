{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train audio: ../train_opus/audio exists: True\n",
      "Test audio: ../test_opus/audio exists: True\n",
      "word_bounds.json: ../train_opus/word_bounds.json exists: True\n"
     ]
    }
   ],
   "source": [
    "import json, random\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\".\")\n",
    "DATA_DIR = ROOT / \"..\"\n",
    "TRAIN_DIR = DATA_DIR / \"train_opus\"\n",
    "TEST_DIR  = DATA_DIR / \"test_opus\"\n",
    "train_audio_dir = TRAIN_DIR / \"audio\"\n",
    "test_audio_dir = TEST_DIR / \"audio\"\n",
    "word_bounds_path = TRAIN_DIR / \"word_bounds.json\"\n",
    "print(\"Train audio:\", train_audio_dir, \"exists:\", train_audio_dir.exists())\n",
    "print(\"Test audio:\", test_audio_dir, \"exists:\", test_audio_dir.exists())\n",
    "print(\"word_bounds.json:\", word_bounds_path, \"exists:\", word_bounds_path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 90000 pos: 45000 neg: 45000\n",
      "Test size: 27000\n"
     ]
    }
   ],
   "source": [
    "with open(word_bounds_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    bounds = json.load(f)\n",
    "\n",
    "train_files = sorted(train_audio_dir.glob(\"*.opus\"))\n",
    "test_files  = sorted(test_audio_dir.glob(\"*.opus\"))\n",
    "\n",
    "train_ids = [p.stem for p in train_files]\n",
    "test_ids  = [p.stem for p in test_files]\n",
    "\n",
    "labels = {tid: (1 if tid in bounds else 0) for tid in train_ids}\n",
    "\n",
    "num_pos = sum(labels.values())\n",
    "num_neg = len(labels) - num_pos\n",
    "print(\"Train size:\", len(train_ids), \"pos:\", num_pos, \"neg:\", num_neg)\n",
    "print(\"Test size:\", len(test_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SR = 16000\n",
    "WIN_SEC = 2.5\n",
    "WIN_SAMPLES = int(SR * WIN_SEC)\n",
    "\n",
    "N_MELS = 64\n",
    "N_FFT = 400\n",
    "HOP = 160\n",
    "\n",
    "mel_tf = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SR, n_fft=N_FFT, hop_length=HOP, n_mels=N_MELS, power=2.0\n",
    ")\n",
    "db_tf = torchaudio.transforms.AmplitudeToDB(stype=\"power\")\n",
    "\n",
    "def load_audio(path: Path, target_sr=SR):\n",
    "    wav, sr = torchaudio.load(str(path))\n",
    "    if wav.shape[0] > 1:\n",
    "        wav = wav.mean(dim=0, keepdim=True)\n",
    "    if sr != target_sr:\n",
    "        wav = torchaudio.functional.resample(wav, sr, target_sr)\n",
    "    return wav.squeeze(0)  # [T]\n",
    "\n",
    "def pad_or_crop(wav: torch.Tensor, length: int, start: int = None):\n",
    "    T = wav.numel()\n",
    "    if T >= length:\n",
    "        if start is None:\n",
    "            start = random.randint(0, T - length)\n",
    "        return wav[start:start+length]\n",
    "    # pad\n",
    "    pad_len = length - T\n",
    "    return torch.nn.functional.pad(wav, (0, pad_len))\n",
    "\n",
    "def wav_to_logmel(wav_1d: torch.Tensor):\n",
    "    # wav_1d: [T]\n",
    "    x = wav_1d.unsqueeze(0)  # [1, T]\n",
    "    m = mel_tf(x)            # [1, n_mels, frames]\n",
    "    m = db_tf(m)\n",
    "    m = (m - m.mean()) / (m.std() + 1e-5)\n",
    "    return m  # [1, n_mels, frames]\n",
    "\n",
    "class PhraseDataset(Dataset):\n",
    "    def __init__(self, audio_dir: Path, ids, bounds_dict, labels_dict,\n",
    "                 win_samples=WIN_SAMPLES, sr=SR, train_mode=True):\n",
    "        self.audio_dir = audio_dir\n",
    "        self.ids = ids\n",
    "        self.bounds = bounds_dict\n",
    "        self.labels = labels_dict\n",
    "        self.win = win_samples\n",
    "        self.sr = sr\n",
    "        self.train_mode = train_mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tid = self.ids[idx]\n",
    "        path = self.audio_dir / f\"{tid}.opus\"\n",
    "        y = self.labels[tid]\n",
    "        wav = load_audio(path, self.sr)\n",
    "        T = wav.numel()\n",
    "\n",
    "        if self.train_mode:\n",
    "            if y == 1:\n",
    "                st, en = self.bounds[tid]\n",
    "                st_s = int(max(0, st * self.sr))\n",
    "                en_s = int(min(T, en * self.sr))\n",
    "                center = (st_s + en_s) // 2\n",
    "\n",
    "                jitter = int(0.2 * self.win)\n",
    "                start = center - self.win // 2 + random.randint(-jitter, jitter)\n",
    "                start = max(0, min(start, max(0, T - self.win)))\n",
    "                chunk = pad_or_crop(wav, self.win, start=start)\n",
    "            else:\n",
    "                chunk = pad_or_crop(wav, self.win, start=None)\n",
    "        else:\n",
    "            start = 0 if T <= self.win else (T - self.win)//2\n",
    "            chunk = pad_or_crop(wav, self.win, start=start)\n",
    "\n",
    "        feat = wav_to_logmel(chunk)\n",
    "        return feat, torch.tensor(y, dtype=torch.float32), tid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 76500 val: 13500\n"
     ]
    }
   ],
   "source": [
    "all_ids = train_ids\n",
    "y_all = [labels[i] for i in all_ids]\n",
    "\n",
    "train_ids_split, val_ids_split = train_test_split(\n",
    "    all_ids, test_size=0.15, random_state=SEED, stratify=y_all\n",
    ")\n",
    "\n",
    "train_ds = PhraseDataset(train_audio_dir, train_ids_split, bounds, labels, train_mode=True)\n",
    "val_ds   = PhraseDataset(train_audio_dir, val_ids_split, bounds, labels, train_mode=False)\n",
    "\n",
    "BATCH = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH, shuffle=False)\n",
    "\n",
    "print(\"train:\", len(train_ds), \"val:\", len(val_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, 1, n_mels, frames]\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
    "        logits = self.head(x).squeeze(-1)\n",
    "        return logits\n",
    "\n",
    "model = SimpleCNN().to(DEVICE)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 27745\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(y_true, y_pred_bin):\n",
    "    y_true = torch.tensor(y_true).int()\n",
    "    y_pred = torch.tensor(y_pred_bin).int()\n",
    "\n",
    "    pos = (y_true == 1)\n",
    "    neg = (y_true == 0)\n",
    "\n",
    "    NUM_POS = pos.sum().item()\n",
    "    NUM_NEG = neg.sum().item()\n",
    "\n",
    "    FN = ((y_true == 1) & (y_pred == 0)).sum().item()\n",
    "    FP = ((y_true == 0) & (y_pred == 1)).sum().item()\n",
    "\n",
    "    FRR = FN / NUM_POS if NUM_POS > 0 else 0.0\n",
    "    FAR = FP / NUM_NEG if NUM_NEG > 0 else 0.0\n",
    "\n",
    "    a = 1.0 - FRR\n",
    "    b = 1.0 - FAR\n",
    "    hm = 0.0 if (a + b) == 0 else 2 * a * b / (a + b)\n",
    "    return hm, FRR, FAR, FN, FP, NUM_POS, NUM_NEG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 1196/1196 [25:44<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.6222 | val_score=0.6756 thr=0.19 FRR=0.296 FAR=0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/8: 100%|██████████| 1196/1196 [29:25<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=0.5613 | val_score=0.7027 thr=0.51 FRR=0.301 FAR=0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/8: 100%|██████████| 1196/1196 [28:32<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.5277 | val_score=0.7239 thr=0.28 FRR=0.271 FAR=0.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/8: 100%|██████████| 1196/1196 [27:28<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=0.5059 | val_score=0.7354 thr=0.66 FRR=0.269 FAR=0.260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/8: 100%|██████████| 1196/1196 [27:38<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=0.4896 | val_score=0.7518 thr=0.57 FRR=0.241 FAR=0.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/8: 100%|██████████| 1196/1196 [26:54<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=0.4766 | val_score=0.7575 thr=0.43 FRR=0.230 FAR=0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/8: 100%|██████████| 1196/1196 [28:29<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=0.4660 | val_score=0.7621 thr=0.19 FRR=0.235 FAR=0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/8: 100%|██████████| 1196/1196 [24:41<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=0.4588 | val_score=0.7651 thr=0.85 FRR=0.213 FAR=0.255\n",
      "Best val score: 0.7650515995872033 best_thr: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(model, loader):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    ys = []\n",
    "    for x, y, _ in loader:\n",
    "        x = x.to(DEVICE, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        p = torch.sigmoid(logits).cpu()\n",
    "        probs.extend(p.tolist())\n",
    "        ys.extend(y.tolist())\n",
    "    return ys, probs\n",
    "\n",
    "def find_best_threshold(y_true, probs):\n",
    "    best = (-1, 0.5, None)\n",
    "    for t in [i/100 for i in range(5, 96)]:\n",
    "        pred = [1 if p >= t else 0 for p in probs]\n",
    "        score, FRR, FAR, *_ = compute_score(y_true, pred)\n",
    "        if score > best[0]:\n",
    "            best = (score, t, (FRR, FAR))\n",
    "    return best  # (score, thr, (FRR,FAR))\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "EPOCHS = 8\n",
    "\n",
    "best_val = -1\n",
    "best_state = None\n",
    "best_thr = 0.5\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x, y, _ in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\"):\n",
    "        x = x.to(DEVICE, non_blocking=True)\n",
    "        y = y.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    y_true, probs = eval_model(model, val_loader)\n",
    "    val_score, thr, (FRR, FAR) = find_best_threshold(y_true, probs)\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss={avg_loss:.4f} | val_score={val_score:.4f} thr={thr:.2f} FRR={FRR:.3f} FAR={FAR:.3f}\")\n",
    "\n",
    "    if val_score > best_val:\n",
    "        best_val = val_score\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        best_thr = thr\n",
    "\n",
    "print(\"Best val score:\", best_val, \"best_thr:\", best_thr)\n",
    "model.load_state_dict(best_state)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict test: 100%|██████████| 27000/27000 [09:16<00:00, 48.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20550, 27000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def predict_file_prob(model, path: Path, win_samples=WIN_SAMPLES, hop_ratio=0.5, batch_windows=64):\n",
    "    model.eval()\n",
    "    wav = load_audio(path, SR)\n",
    "    T = wav.numel()\n",
    "    if T <= win_samples:\n",
    "        feat = wav_to_logmel(pad_or_crop(wav, win_samples, start=0)).unsqueeze(0).to(DEVICE)\n",
    "        p = torch.sigmoid(model(feat)).item()\n",
    "        return p\n",
    "\n",
    "    hop = int(win_samples * hop_ratio)\n",
    "    starts = list(range(0, max(1, T - win_samples + 1), hop))\n",
    "    if starts[-1] != T - win_samples:\n",
    "        starts.append(T - win_samples)\n",
    "\n",
    "    probs = []\n",
    "    batch = []\n",
    "    for s in starts:\n",
    "        chunk = wav[s:s+win_samples]\n",
    "        feat = wav_to_logmel(chunk)\n",
    "        batch.append(feat)\n",
    "        if len(batch) == batch_windows:\n",
    "            x = torch.stack(batch, dim=0).to(DEVICE)\n",
    "            p = torch.sigmoid(model(x)).detach().cpu()\n",
    "            probs.extend(p.tolist())\n",
    "            batch = []\n",
    "    if batch:\n",
    "        x = torch.stack(batch, dim=0).to(DEVICE)\n",
    "        p = torch.sigmoid(model(x)).detach().cpu()\n",
    "        probs.extend(p.tolist())\n",
    "\n",
    "    return float(max(probs))\n",
    "\n",
    "\n",
    "test_probs = []\n",
    "for p in tqdm(test_files, desc=\"Predict test\"):\n",
    "    test_probs.append(predict_file_prob(model, p))\n",
    "\n",
    "test_pred = [1 if pr >= best_thr else 0 for pr in test_probs]\n",
    "sum(test_pred), len(test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                         id  label\n",
       " 0  0000219778122723066859323624505982384475      0\n",
       " 1  0000920560142346477464477964040846645823      1\n",
       " 2  0002106775361063830068199242310438122126      1\n",
       " 3  0002161736146841817059430282255903999813      0\n",
       " 4  0002303832386140303186933286284938192307      0,\n",
       " 'submition.csv')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sub = pd.DataFrame({\"id\": test_ids, \"label\": test_pred})\n",
    "sub_path = \"submition.csv\"\n",
    "sub.to_csv(sub_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
